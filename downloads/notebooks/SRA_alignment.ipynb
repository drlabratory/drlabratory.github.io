{
 "metadata": {
  "name": "",
  "signature": "sha256:dffd3085434149550a587e08c675d2b9a06b5f0666200effbb06ed23928109a5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background  \n",
      "I have genomic data collected on 10 strains of *Cryptococcus neoformans*, a human fungal pathogen. It was collected a few years ago, and is, in a word, terrible. It is SOLiD3 or SOLid4 50bp single end data, 20M-30M reads per sample, but a best half survive quality trimming. In an attempt to salvage something out of the data, I noticed that while coverage of the genome was pretty awful, coverage of the mitochondria wasn't bad. Even better, while mapping is very sensitive to using the right variant (*var neoformans*, common name JEC21 vs *var grubii*, common name H99), the mitochondrial sequence of H99 appears good enough to map either. To double check, I wondered if NCBI had published their raw data for the JEC21 sequence. I didn't find it, but what I did find was something even better, a veritable gold mine: 27 strains of *C. neoformans*, all determined to at least 500X using a combination of paried end and single end Illumina.\n",
      "\n",
      "This is an odd case of open science, in that the Broad Institute has deposited the raw read data and I can't find a manuscript to go with it! I've contacted a person at Duke who I think is working on it, but so far (two weeks later) have received no response. As expected from Broad, the data is amazing, and the proper controls have been done, including resequencing the reference strain, H99. Out of curiousity, I decided to download a read set and try mapping it in order to get some experience working with good data.  On pulling up the SAM files in Geneious, I saw something kind of odd: it was obvious that certain positions in the mitochondria contained multiple valid reads for different sequences.  So I did the logical next step; ask someone on twitter for help:  \n",
      "\n",
      "<blockquote class=\"twitter-tweet\"><p>@<a href=\"https://twitter.com/drlabratory\">drlabratory</a> do you mean single species? there is lots but you need to search for population genetics, phylogeography to find it ..</p>&mdash; Jonathan Eisen (@phylogenomics) <a href=\"https://twitter.com/phylogenomics/status/292669195919958016\">January 19, 2013</a></blockquote>\n",
      "<blockquote class=\"twitter-tweet\"><p>@<a href=\"https://twitter.com/drlabratory\">drlabratory</a> ahh .. you want mitochondrial heteroplasmy</p>&mdash; Jonathan Eisen (@phylogenomics) <a href=\"https://twitter.com/phylogenomics/status/292677187583234048\">January 19, 2013</a></blockquote>\n",
      "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
      "\n",
      "Ok, it wasn't just anyone. It still blows me away that Jonathan is so generous with his time over twitter.  Anyway, with that simple exchange, a new project (to me, remember I have no idea what the folks at Broad are doing with this data) was born. I hope to address what mitochondrial heteroplasmy is and means (if anything) in the next post, but for the time being I just wanted to know it it existed in significant quantity in *C. neoformans*. It would be tempting to think so, as mating in this fungi consist of nuclear fusion, but surprisingly... [no](http://www.ncbi.nlm.nih.gov/pubmed/10688697). Even more strange (to me), [mating factor type](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3385124/) seems to determine which population \"wins\" after nuclear fusion. The caveat to those two papers is that they weren't measured by high coverage sequencing, and I know what I saw. \n",
      " \n",
      "After the fold are the programs/strategies for manipulating the raw read data into a Variant Call Format file. My choice of programs are somewhat arbitrary. [FreeBayes](https://github.com/ekg/freebayes) has a \"ploidy\" and \"pooled\" option that seem to do what I want: treat the mitochondria like a population of bacteria. I used [Novoalign](http://www.novocraft.com/main/index.php) because I had a free 30 day trial and wanted to put it through its paces with some good data, and [Mick Watson](https://twitter.com/BioMickWatson) sings its praises re:accuracy, which seems relatively important for this analysis. The rest is my kludgy python. This ipython notebook is saved to my public github repository, found [here](https://github.com/drlabratory/Research_Git/tree/master/sequence_analysis)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Data file manipulation  \n",
      "First I needed to get the data, all 100+ GB of it.\n",
      "- downloaded the entire [SRP015886](http://www.ncbi.nlm.nih.gov/sra/?term=SRP015886) experiment runs and converted them to FASTQ using [fastq-dump](http://www.ncbi.nlm.nih.gov/Traces/sra/?view=software) in a bash script.\n",
      "- Ran [Trimmomatic](http://www.usadellab.org/cms/index.php?page=trimmomatic) on all with the following options (bash script as well):\n",
      "\n",
      "Paired end:  \n",
      "\n",
      "    java -classpath /usr/local/Trimmomatic-0.22/trimmomatic-0.22.jar \\\n",
      "        org.usadellab.trimmomatic.TrimmomaticPE -threads 8 -phred33 -trimlog \\\n",
      "        $dir.trim.log $dir\\_1.fastq.gz $dir\\_2.fastq.gz \\\n",
      "        $dir\\_paired_1.fq.gz $dir\\_unpaired_1.fq.gz \\\n",
      "        $dir\\_paired_2.fq.gz $dir\\_unpaired_2.fq.gz \\\n",
      "        ILLUMINACLIP:../illuminaClip.fa:2:40:15 LEADING:15 \\\n",
      "        TRAILING:15 SLIDINGWINDOW:4:20 MINLEN:36\n",
      "\n",
      "Single end:\n",
      "\n",
      "    java -classpath /usr/local/Trimmomatic-0.22/trimmomatic-0.22.jar \\\n",
      "        org.usadellab.trimmomatic.TrimmomaticSE -threads 8 -phred33 -trimlog \\\n",
      "        $dir.trim.log $dir.fastq.gz \\\n",
      "        $dir\\_trimmed.fq.gz  \\\n",
      "        ILLUMINACLIP:../illuminaClip.fa:2:40:15 LEADING:15 \\\n",
      "        TRAILING:15 SLIDINGWINDOW:4:20 MINLEN:36\n",
      "\n",
      "Downloaded the SRP015886.xml from the [ENA](http://www.ebi.ac.uk/ena/data/view/SRP015886) at EBI (note to self, always get read data from ENA when possible)\n",
      "\n",
      "These were also all done before I figured out that variables are share between cells in iPython notebooks, so reading in the XML file every time in order to do a new analysis is totally uneccesary. But changing it after the fact would be a waste of time. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Ran novoindex on the H99.fasta file\n",
      "Fasta download from [Broad](http://www.broadinstitute.org/annotation/genome/cryptococcus_neoformans/MultiHome.html) for both genome and mitochondria, cat'ed together. \n",
      "\n",
      "    novoindex H99.nix H99.fasta"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Wrote python blurb to create bash script\n",
      "Reads in the XML, looks for all the runs, then extracts read length and sdev when appropriate. Novoalign can use read length and sdev. Mapped all the read files seperately, as [Novoalign suggests](http://www.novocraft.com/wiki/tiki-view_forum_thread.php?topics_offset=1&forumId=1&comments_parentId=535) doing that and then merging the SAM files.  \n",
      "As it will take 2-3 days, running mapping from within python notebook seemed like a bad idea, hence the scripts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('SRP015886.xml')\n",
      "root = tree.getroot()\n",
      "\n",
      "f = open('align_all.sh', 'w')\n",
      "f.write(\"#!/bin/bash\\n\")\n",
      "\n",
      "for child in root:\n",
      "    ID = child.find('IDENTIFIERS').find('PRIMARY_ID').text\n",
      "    try:\n",
      "        paired = child.find('DESIGN').find('LIBRARY_DESCRIPTOR').find('LIBRARY_LAYOUT').find('PAIRED')\n",
      "        pdev = int(float(paired.attrib['NOMINAL_SDEV']))\n",
      "        plength = int(float(paired.attrib['NOMINAL_LENGTH']))\n",
      "    except AttributeError:\n",
      "        pdev = 0\n",
      "        plength = 0\n",
      "    links = child.find('EXPERIMENT_LINKS')\n",
      "    for exps in links:\n",
      "        if exps.find('XREF_LINK').find('DB').text == 'ENA-RUN':\n",
      "            runs = exps.find('XREF_LINK').find('ID').text.split(',')\n",
      "            for lanes in runs:\n",
      "                if pdev:\n",
      "                    f.write(\"cd %s\\n\" % (lanes))\n",
      "                    f.write(\"novoalign -o SAM -d ../H99.nix -f %s_paired_1.fq.gz %s_paired_2.fq.gz -i %i,%i > %s_H99.SAM \\n\" % \\\n",
      "                            (lanes,lanes,plength,pdev,lanes))\n",
      "                    f.write(\"cd ..\\n\")\n",
      "                else:\n",
      "                    f.write(\"cd %s\\n\" % (lanes))\n",
      "                    f.write(\"novoalign -o SAM -d ../H99.nix -f %s_trimmed.fq.gz > %s_H99.SAM \\n\" % \\\n",
      "                            (lanes,lanes))\n",
      "                    f.write(\"cd ..\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Screwed up and missed SRR646261-SRR646262, should be SRR646261,SRR646262.  \n",
      "For reasons that aren't clear, certain runs are denoted in the XML file as a range (SRR646261-SRR646262 in this example, but there are others), while most are a list.  \n",
      "Had to run from that point on.  Now need to make a list of samples and their associated SAM/BAM files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('SRP015886.xml')\n",
      "root = tree.getroot()\n",
      "\n",
      "samples = {}\n",
      "\n",
      "for child in root:\n",
      "    ID = child.find('DESIGN').find('SAMPLE_DESCRIPTOR').attrib['refname']\n",
      "    cellsplit = ID.split(' ')\n",
      "    sample = cellsplit[len(cellsplit)-1].strip()\n",
      "    links = child.find('EXPERIMENT_LINKS')\n",
      "    for exps in links:\n",
      "        if exps.find('XREF_LINK').find('DB').text == 'ENA-RUN':\n",
      "            runs = exps.find('XREF_LINK').find('ID').text.split(',')\n",
      "    if samples.has_key(sample):\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "    else:\n",
      "        samples[sample]=[]\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "\n",
      "f = open('sam_merge.sh', 'w')\n",
      "f.write(\"#!/bin/bash\\n\")\n",
      "for keys in samples:\n",
      "    f.write(\"mkdir %s\\n\" % keys)\n",
      "    sams = []\n",
      "    for dirs in samples[keys]:\n",
      "        sams.append(dirs+\".bam\")\n",
      "        f.write(\"cd %s\\n\" % dirs)\n",
      "        f.write(\"samtools view -bS %s_H99.SAM > %s_H99.bam\\n\" % (dirs,dirs))\n",
      "        f.write(\"rm %s_H99.SAM\\n\" % dirs)\n",
      "        f.write(\"ln -s %s_H99.bam ../%s/%s.bam\\n\" % (dirs,keys,dirs))\n",
      "        f.write(\"cd ..\\n\")\n",
      "    f.write(\"cd %s\\n\" % keys)\n",
      "    f.write(\"samtools merge %s.bam %s\\n\" % (keys,' '.join(sams)))\n",
      "    f.write(\"samtools sort %s.bam %s.sorted\\n\" % (keys,keys))\n",
      "    f.write(\"samtools index %s.sorted.bam\\n\" % keys)\n",
      "    f.write(\"cd ..\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Damnit, apparently that link command doesn't work, need to write another cleanup script.  \n",
      "I've also noticed that the forum suggested sorting, then merging. This merges, then sorts. Hrm.  \n",
      "The new BAM files are named from the XML, by strain name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('SRP015886.xml')\n",
      "root = tree.getroot()\n",
      "\n",
      "samples = {}\n",
      "\n",
      "for child in root:\n",
      "    ID = child.find('DESIGN').find('SAMPLE_DESCRIPTOR').attrib['refname']\n",
      "    cellsplit = ID.split(' ')\n",
      "    sample = cellsplit[len(cellsplit)-1].strip()\n",
      "    links = child.find('EXPERIMENT_LINKS')\n",
      "    for exps in links:\n",
      "        if exps.find('XREF_LINK').find('DB').text == 'ENA-RUN':\n",
      "            runs = exps.find('XREF_LINK').find('ID').text.split(',')\n",
      "    if samples.has_key(sample):\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "    else:\n",
      "        samples[sample]=[]\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "\n",
      "f = open('sam_cleanup.sh', 'w')\n",
      "f.write(\"#!/bin/bash\\n\")\n",
      "for keys in samples:\n",
      "    sams = []\n",
      "    for dirs in samples[keys]:\n",
      "        sams.append(dirs+\"_H99.bam\")\n",
      "    f.write(\"cd %s\\n\" % keys)\n",
      "    f.write(\"samtools merge %s.bam %s\\n\" % (keys,' '.join(sams)))\n",
      "    f.write(\"samtools sort %s.bam %s.sorted\\n\" % (keys,keys))\n",
      "    f.write(\"samtools index %s.sorted.bam\\n\" % keys)\n",
      "    f.write(\"cd ..\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Running Freebayes with ploidy 4\n",
      "Before finding out about a different strategy below, tried --ploidy 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('SRP015886.xml')\n",
      "root = tree.getroot()\n",
      "\n",
      "samples = {}\n",
      "\n",
      "for child in root:\n",
      "    ID = child.find('DESIGN').find('SAMPLE_DESCRIPTOR').attrib['refname']\n",
      "    cellsplit = ID.split(' ')\n",
      "    sample = cellsplit[len(cellsplit)-1].strip()\n",
      "    links = child.find('EXPERIMENT_LINKS')\n",
      "    for exps in links:\n",
      "        if exps.find('XREF_LINK').find('DB').text == 'ENA-RUN':\n",
      "            runs = exps.find('XREF_LINK').find('ID').text.split(',')\n",
      "    if samples.has_key(sample):\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "    else:\n",
      "        samples[sample]=[]\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "\n",
      "f = open('variant_call.sh', 'w')\n",
      "f.write(\"#!/bin/bash\\n\")\n",
      "for keys in samples:\n",
      "    f.write(\"cd %s\\n\" % keys)\n",
      "    f.write(\"samtools view -b %s.sorted.bam H99_mitochondria > %s_mito.bam\\n\" % (keys,keys))\n",
      "    f.write(\"samtools index %s_mito.bam\\n\" % keys)\n",
      "    f.write(\"freebayes -0 -b %s_mito.bam -f ../H99_mitochondria.fasta -v %s_mito_ploidy4.vcf --ploidy 4 --min-alternate-fraction 0.01 --max-complex-gap 50\\n\" % (keys,keys))\n",
      "    f.write(\"cd ..\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Different FreeBayes run  \n",
      "According to this wiki at [UTexas](https://wikis.utexas.edu/display/bioiteam/Genome+variation+in+mixed+samples+(FreeBayes,+deepSNV)), mixed bacteria can be tested using --ploidy 100 and --pooled. This matches what I've been thinking in the first place: just treat all the mitochondria in the cell as a mixed population of bacteria."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('SRP015886.xml')\n",
      "root = tree.getroot()\n",
      "\n",
      "samples = {}\n",
      "\n",
      "for child in root:\n",
      "    ID = child.find('DESIGN').find('SAMPLE_DESCRIPTOR').attrib['refname']\n",
      "    cellsplit = ID.split(' ')\n",
      "    sample = cellsplit[len(cellsplit)-1].strip()\n",
      "    links = child.find('EXPERIMENT_LINKS')\n",
      "    for exps in links:\n",
      "        if exps.find('XREF_LINK').find('DB').text == 'ENA-RUN':\n",
      "            runs = exps.find('XREF_LINK').find('ID').text.split(',')\n",
      "    if samples.has_key(sample):\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "    else:\n",
      "        samples[sample]=[]\n",
      "        for names in runs:\n",
      "            samples[sample].append(names)\n",
      "\n",
      "f = open('freebayes100.sh', 'w')\n",
      "f.write(\"#!/bin/bash\\n\")\n",
      "for keys in samples:\n",
      "    f.write(\"cd %s\\n\" % keys)\n",
      "    f.write(\"freebayes -b %s_mito.bam -f ../H99_mitochondria.fasta -v %s_mito_ploidy100.vcf --ploidy 100 --pooled --min-alternate-total 3 --max-complex-gap 50\\n\" % (keys,keys))\n",
      "    f.write(\"cd ..\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK! Now I have 27 vcf files, I need a way to visualize what is going on. Tomorrow I will post my visualization of the data in iPython notebook and matplotlib."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}